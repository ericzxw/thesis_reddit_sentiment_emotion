{"cells":[{"cell_type":"markdown","source":["# Following shows the steps of collecting comments for users with SRDD by using PullPush API.\n","\n","- pullpush API for reddit data search: https://pullpush.io/\n","- each user's comments are stored as json file in the end"],"metadata":{"id":"utSNzJvKhXfh"},"id":"utSNzJvKhXfh"},{"cell_type":"markdown","id":"b619f96c","metadata":{"id":"b619f96c"},"source":["### Scraping Data"]},{"cell_type":"code","execution_count":null,"id":"78a29be5","metadata":{"id":"78a29be5"},"outputs":[],"source":["# From 2019 to 2023, each month is seperated to avoid hitting the limit rate of API request.\n","date_ranges = [\n","    (\"1546300800\", \"1548979200\"),  # 2019-01-01 to 2019-01-31\n","    (\"1548979200\", \"1551398400\"),  # 2019-02-01 to 2019-02-28\n","    (\"1551398400\", \"1554076800\"),  # 2019-03-01 to 2019-03-31\n","    (\"1554076800\", \"1556668800\"),  # 2019-04-01 to 2019-04-30\n","    (\"1556668800\", \"1559347200\"),  # 2019-05-01 to 2019-05-31\n","    (\"1559347200\", \"1561939200\"),  # 2019-06-01 to 2019-06-30\n","    (\"1561939200\", \"1564617600\"),  # 2019-07-01 to 2019-07-31\n","    (\"1564617600\", \"1567296000\"),  # 2019-08-01 to 2019-08-31\n","    (\"1567296000\", \"1569888000\"),  # 2019-09-01 to 2019-09-30\n","    (\"1569888000\", \"1572566400\"),  # 2019-10-01 to 2019-10-31\n","    (\"1572566400\", \"1575158400\"),  # 2019-11-01 to 2019-11-30\n","    (\"1575158400\", \"1577836800\"),  # 2019-12-01 to 2019-12-31\n","    (\"1577836800\", \"1580515200\"),  # 2020-01-01 to 2020-01-31\n","    (\"1580515200\", \"1583020800\"),  # 2020-02-01 to 2020-02-29 (leap year)\n","    (\"1583020800\", \"1585699200\"),  # 2020-03-01 to 2020-03-31\n","    (\"1585699200\", \"1588291200\"),  # 2020-04-01 to 2020-04-30\n","    (\"1588291200\", \"1590969600\"),  # 2020-05-01 to 2020-05-31\n","    (\"1590969600\", \"1593475200\"),  # 2020-06-01 to 2020-06-30\n","    (\"1593475200\", \"1596153600\"),  # 2020-07-01 to 2020-07-31\n","    (\"1596153600\", \"1598832000\"),  # 2020-08-01 to 2020-08-31\n","    (\"1598832000\", \"1601424000\"),  # 2020-09-01 to 2020-09-30\n","    (\"1601424000\", \"1604102400\"),  # 2020-10-01 to 2020-10-31\n","    (\"1604102400\", \"1606694400\"),  # 2020-11-01 to 2020-11-30\n","    (\"1606694400\", \"1609372800\"),  # 2020-12-01 to 2020-12-31\n","    (\"1609372800\", \"1612051200\"),  # 2021-01-01 to 2021-01-31\n","    (\"1612051200\", \"1614470400\"),  # 2021-02-01 to 2021-02-28\n","    (\"1614470400\", \"1617148800\"),  # 2021-03-01 to 2021-03-31\n","    (\"1617148800\", \"1619740800\"),  # 2021-04-01 to 2021-04-30\n","    (\"1619740800\", \"1622419200\"),  # 2021-05-01 to 2021-05-31\n","    (\"1622419200\", \"1625011200\"),  # 2021-06-01 to 2021-06-30\n","    (\"1625011200\", \"1627689600\"),  # 2021-07-01 to 2021-07-31\n","    (\"1627689600\", \"1630368000\"),  # 2021-08-01 to 2021-08-31\n","    (\"1630368000\", \"1632960000\"),  # 2021-09-01 to 2021-09-30\n","    (\"1632960000\", \"1635638400\"),  # 2021-10-01 to 2021-10-31\n","    (\"1635638400\", \"1638230400\"),  # 2021-11-01 to 2021-11-30\n","    (\"1638230400\", \"1640908800\"),  # 2021-12-01 to 2021-12-31\n","    (\"1640908800\", \"1643587200\"),  # 2022-01-01 to 2022-01-31\n","    (\"1643587200\", \"1646006400\"),  # 2022-02-01 to 2022-02-28\n","    (\"1646006400\", \"1648684800\"),  # 2022-03-01 to 2022-03-31\n","    (\"1648684800\", \"1651276800\"),  # 2022-04-01 to 2022-04-30\n","    (\"1651276800\", \"1653955200\"),  # 2022-05-01 to 2022-05-31\n","    (\"1653955200\", \"1656547200\"),  # 2022-06-01 to 2022-06-30\n","    (\"1656547200\", \"1659225600\"),  # 2022-07-01 to 2022-07-31\n","    (\"1659225600\", \"1661904000\"),  # 2022-08-01 to 2022-08-31\n","    (\"1661904000\", \"1664496000\"),  # 2022-09-01 to 2022-09-30\n","    (\"1664496000\", \"1667174400\"),  # 2022-10-01 to 2022-10-31\n","    (\"1667174400\", \"1669766400\"),  # 2022-11-01 to 2022-11-30\n","    (\"1669766400\", \"1672444800\"),  # 2022-12-01 to 2022-12-31\n","    (\"1672444800\", \"1675123200\"),  # 2023-01-01 to 2023-01-31\n","    (\"1675123200\", \"1677542400\"),  # 2023-02-01 to 2023-02-28\n","    (\"1677542400\", \"1680220800\"),  # 2023-03-01 to 2023-03-31\n","    (\"1680220800\", \"1682812800\"),  # 2023-04-01 to 2023-04-30\n","    (\"1682812800\", \"1685491200\"),  # 2023-05-01 to 2023-05-31\n","    (\"1685491200\", \"1688083200\"),  # 2023-06-01 to 2023-06-30\n","    (\"1688083200\", \"1690761600\"),  # 2023-07-01 to 2023-07-31\n","    (\"1690761600\", \"1693440000\"),  # 2023-08-01 to 2023-08-31\n","    (\"1693440000\", \"1696032000\"),  # 2023-09-01 to 2023-09-30\n","    (\"1696032000\", \"1698710400\"),  # 2023-10-01 to 2023-10-31\n","    (\"1698710400\", \"1701302400\"),  # 2023-11-01 to 2023-11-30\n","    (\"1701302400\", \"1703980800\")   # 2023-12-01 to 2023-12-31\n","]\n"]},{"cell_type":"code","execution_count":null,"id":"b46910f0","metadata":{"scrolled":true,"id":"b46910f0"},"outputs":[],"source":["# begin collection, before this step, the author list is kept in a seperate csv file.\n","import pandas as pd\n","part_df = pd.read_csv('authors_SRDD.csv', encoding='latin1')\n"]},{"cell_type":"code","execution_count":null,"id":"a8134f3e","metadata":{"scrolled":true,"id":"a8134f3e"},"outputs":[],"source":["part_df['author']"]},{"cell_type":"code","execution_count":null,"id":"a41f7e20","metadata":{"id":"a41f7e20"},"outputs":[],"source":["import requests\n","import time\n","import json\n","import os\n","from requests.exceptions import SSLError, ConnectionError\n","\n","def fetch_data(author, start_epoch, end_epoch, retries=1):\n","    url = \"https://api.pullpush.io/reddit/search/comment/\"\n","    params = {\n","        \"author\": author,\n","        \"after\": start_epoch,\n","        \"before\": end_epoch,\n","    }\n","\n","    attempt = 0\n","    while attempt <= retries:\n","        try:\n","            response = requests.get(url, params=params)\n","            if response.status_code == 200:\n","                return response.json()\n","            else:\n","                print(f\"Error fetching data for {author} from {start_epoch} to {end_epoch}: {response.status_code}\")\n","        except (SSLError, ConnectionError) as e:\n","            print(f\"Connection error ({e}) for {author} from {start_epoch} to {end_epoch}, attempt {attempt + 1} of {retries + 1}\")\n","\n","        # if not sucessful, wait for another 5 seconds\n","        wait_time = 5  #\n","        print(f\"Waiting for {wait_time} seconds before retrying...\")\n","        time.sleep(wait_time)\n","        attempt += 1\n","\n","    # if all retries run out, return none\n","    print(f\"Failed to fetch data for {author} from {start_epoch} to {end_epoch} after {retries + 1} attempts\")\n","    return None\n","\n","# get all authors with SRDD\n","authors = part_df['author'].unique()\n","\n","for author in authors:\n","    merged_data = []\n","    print(f\"Collecting for user: {author}\")\n","    # Fetch data for each date range for the current author\n","    for start_epoch, end_epoch in date_ranges:\n","        data = fetch_data(author, start_epoch, end_epoch)\n","        if data is None:  # if the data is none, skip this time period\n","            continue\n","        if data.get(\"data\"):\n","            merged_data.extend(data[\"data\"])\n","        time.sleep(3)  # To avoid hitting rate limits\n","\n","    # Save the merged data to a JSON file named after the author\n","    file_path = os.path.join('depressed\\comment', f'{author}.json')\n","    with open(file_path, 'w') as f:\n","        json.dump(merged_data, f)\n","    print(f\"Collection is done for user:{author}\")\n"]},{"cell_type":"markdown","source":["# Finally, the comments are stored as json files. Each author has one json file that includes all his or her comment row data from 2019 to 2023.\n","\n"],"metadata":{"id":"zyREqAKOibdU"},"id":"zyREqAKOibdU"}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.20"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}