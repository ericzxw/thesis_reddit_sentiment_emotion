{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNAX2XTMPa6ndaQHPRuUg97"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Following shows an example of matching control users for users with SRDD\n","\n","- before this step, you need build the control user pool as stated in the paper, which is from 10 selected non-depression subreddits.\n","- to increase the matching efficiency, this study sampled out a subgroup of control candidates for matching every time."],"metadata":{"id":"mUkf-vHHggkL"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7QzZqsZEQvsd","executionInfo":{"status":"ok","timestamp":1732873826529,"user_tz":-60,"elapsed":1918,"user":{"displayName":"Xinwen Zou","userId":"16274622982732869716"}},"outputId":"6801b1da-1963-4ba5-bdd9-0e1c37a1fff3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import pandas as pd\n","file_path = '/content/drive/MyDrive/Reddit/rematch_list_depressed_windowed.csv' # this is the file of storing users with SRDD\n","file_path2 = '/content/drive/MyDrive/Reddit/candidate_control_authors_info.csv' # this is the file of storing candidate control users\n","\n","rematch_list = pd.read_csv(file_path, encoding='latin1')\n","control_condidates = pd.read_csv(file_path2, encoding='latin1')"]},{"cell_type":"code","source":["rematch_list"],"metadata":{"id":"wgbZo5nURayx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["control_condidates = control_condidates[control_condidates['total_post'].isna()]"],"metadata":{"id":"DxkMZDIXS64y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["control_condidates"],"metadata":{"id":"mNSkkHIsTnVv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from scipy.spatial.distance import mahalanobis\n","\n","# transfer Is_Mod into integer\n","rematch_list['Is_Mod'] = rematch_list['Is_Mod'].astype(int)\n","control_condidates['Is_Mod'] = control_condidates['Is_Mod'].astype(int)\n","\n","# transfer author_created_utc into datetime type\n","rematch_list['year'] = pd.to_datetime(rematch_list['author_created_utc']).dt.year\n","rematch_list['month'] = pd.to_datetime(rematch_list['author_created_utc']).dt.month\n","\n","control_condidates['year'] = pd.to_datetime(control_condidates['author_created_utc'],format='%d/%m/%Y %H:%M:%S').dt.year\n","control_condidates['month'] = pd.to_datetime(control_condidates['author_created_utc'], format='%d/%m/%Y %H:%M:%S').dt.month\n","\n","# ini result list\n","matched_results = []\n","\n","# filter users created in the same year and same month first\n","for year, month in rematch_list[['year', 'month']].drop_duplicates().values:\n","\n","    srdd_subset = rematch_list[(rematch_list['year'] == year) & (rematch_list['month'] == month)]\n","    control_subset = control_condidates[(control_condidates['year'] == year) & (control_condidates['month'] == month)]\n","#    if control_subset.empty:\n","#        control_subset = control_condidates[control_condidates['year'] == year]\n","\n","#    if control_subset.empty:\n","#        print(f\"No control group for year {year}, month {month}. Using all control authors...\")\n","#        control_subset = control_condidates\n","\n","    # four user atrributes were used in matching\n","    dimensions = ['total_post', 'Is_Mod', 'Comment_Karma', 'Link_Karma']\n","    srdd_values = srdd_subset[dimensions].values\n","    control_values = control_subset[dimensions].values\n","\n","    # check whether the sample size is enough\n","    if control_values.shape[0] <= control_values.shape[1]:\n","        print(f\"Not enough samples for year {year}, month {month}. Skipping...\")\n","        continue\n","\n","    # Calculating the covariance matrix and dealing with singularities\n","    cov_matrix = np.cov(control_values, rowvar=False)\n","    try:\n","        inv_cov_matrix = np.linalg.inv(cov_matrix)\n","    except np.linalg.LinAlgError:\n","        print(f\"Singular matrix encountered for year {year}, month {month}. Using pseudo-inverse...\")\n","        inv_cov_matrix = np.linalg.pinv(cov_matrix)\n","\n","    # find the nearest neighbour for each user with SRDD\n","    for idx, srdd_user in srdd_subset.iterrows():\n","        srdd_vector = srdd_user[dimensions].values\n","        min_distance = float('inf')\n","        best_match = None\n","\n","        for _, control_user in control_subset.iterrows():\n","            control_vector = control_user[dimensions].values\n","            distance = mahalanobis(srdd_vector, control_vector, inv_cov_matrix) # compute the mahalanobis distance\n","\n","            if distance < min_distance:\n","                min_distance = distance\n","                best_match = control_user['Username']\n","\n","        # save the matching results\n","        matched_results.append({\n","            'srdd_author': srdd_user['author'],\n","            'matched_control_author': best_match,\n","            'year': year,\n","            'month': month,\n","            'mahalanobis_distance': min_distance\n","        })\n","\n","# save the matching results as data frame\n","matched_results_df = pd.DataFrame(matched_results)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wITSXkeSUBtY","executionInfo":{"status":"ok","timestamp":1732884816387,"user_tz":-60,"elapsed":2101,"user":{"displayName":"Xinwen Zou","userId":"16274622982732869716"}},"outputId":"ca5e15d0-cab9-4ad1-83ae-0688f941e68f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-35-51b4fecf0481>:10: UserWarning: Parsing dates in %d/%m/%Y %H:%M format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n","  rematch_list['year'] = pd.to_datetime(rematch_list['author_created_utc']).dt.year\n","<ipython-input-35-51b4fecf0481>:11: UserWarning: Parsing dates in %d/%m/%Y %H:%M format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n","  rematch_list['month'] = pd.to_datetime(rematch_list['author_created_utc']).dt.month\n"]},{"output_type":"stream","name":"stdout","text":["Not enough samples for year 2017, month 3. Skipping...\n","Not enough samples for year 2018, month 5. Skipping...\n","Not enough samples for year 2016, month 1. Skipping...\n","Not enough samples for year 2014, month 8. Skipping...\n","Not enough samples for year 2010, month 2. Skipping...\n","Not enough samples for year 2015, month 11. Skipping...\n","No control group for year 2023, month 9. Using all control authors...\n","No control group for year 2023, month 2. Using all control authors...\n","No control group for year 2008, month 4. Using all control authors...\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"SFt-reryAYjd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["matched_results_df"],"metadata":{"id":"bKD9D3LcWRZO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["matched_results_df.to_csv('/content/drive/MyDrive/Reddit/rematch_result_windowed.csv',index = False)"],"metadata":{"id":"C_gush7zAZxN"},"execution_count":null,"outputs":[]}]}